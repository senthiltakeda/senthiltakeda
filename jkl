data.terraform_remote_state.stack: Reading...
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-DataAnalyst: Reading...
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-AppAdmin: Reading...
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-DataEngineer: Reading...
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-DataScientist: Reading...
data.terraform_remote_state.stack: Read complete after 0s
module.ds-pdt-forecast-dev_interactive_cluster.data.databricks_spark_version.template: Reading...
module.ds-pdt-forecast-dev_interactive_cluster.data.databricks_spark_version.template: Read complete after 0s [id=12.0.x-cpu-ml-scala2.12]
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-AppAdmin: Read complete after 0s [id=564916208720719]
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-DataAnalyst: Read complete after 1s [id=759602545683727]
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-DataEngineer: Read complete after 1s [id=741847143863456]
data.databricks_group.Okta-DBX-E2-PDT-FORECAST-DataScientist: Read complete after 1s [id=862835692861165]

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # databricks_instance_profile.cluster will be created
  + resource "databricks_instance_profile" "cluster" {
      + id                   = (known after apply)
      + instance_profile_arn = "arn:aws:iam::824757673730:instance-profile/TEC-EC2-DATABRICKS-USPRD-DS-PDT-FORECAST-ROLE"
      + skip_validation      = (known after apply)
    }

  # databricks_mws_permission_assignment.add_Okta-DBX-E2-PDT-FORECAST-AppAdmin_group will be created
  + resource "databricks_mws_permission_assignment" "add_Okta-DBX-E2-PDT-FORECAST-AppAdmin_group" {
      + id           = (known after apply)
      + permissions  = [
          + "USER",
        ]
      + principal_id = 564916208720719
      + workspace_id = 2186391591496286
    }

  # databricks_mws_permission_assignment.add_Okta-DBX-E2-PDT-FORECAST-DataAnalyst_group will be created
  + resource "databricks_mws_permission_assignment" "add_Okta-DBX-E2-PDT-FORECAST-DataAnalyst_group" {
      + id           = (known after apply)
      + permissions  = [
          + "USER",
        ]
      + principal_id = 759602545683727
      + workspace_id = 2186391591496286
    }

  # databricks_mws_permission_assignment.add_Okta-DBX-E2-PDT-FORECAST-DataEngineer_group will be created
  + resource "databricks_mws_permission_assignment" "add_Okta-DBX-E2-PDT-FORECAST-DataEngineer_group" {
      + id           = (known after apply)
      + permissions  = [
          + "USER",
        ]
      + principal_id = 741847143863456
      + workspace_id = 2186391591496286
    }

  # databricks_mws_permission_assignment.add_Okta-DBX-E2-PDT-FORECAST-DataScientist_group will be created
  + resource "databricks_mws_permission_assignment" "add_Okta-DBX-E2-PDT-FORECAST-DataScientist_group" {
      + id           = (known after apply)
      + permissions  = [
          + "USER",
        ]
      + principal_id = 862835692861165
      + workspace_id = 2186391591496286
    }

  # module.ds-pdt-forecast-dev_interactive_cluster.databricks_cluster.template will be created
  + resource "databricks_cluster" "template" {
      + autotermination_minutes      = 120
      + cluster_id                   = (known after apply)
      + cluster_name                 = "DS-PDT-FORECAST-DEV"
      + custom_tags                  = {
          + "ResourceClass"        = "Classic"
          + "Team"                 = "databricks"
          + "account-type"         = "Production"
          + "app"                  = "Plasma Forecast Scenario Planning"
          + "application-owner"    = "jeff.hoverson@takeda.com"
          + "business-criticality" = "High"
          + "business-unit-n1"     = "PDT IT"
          + "business-unit-n2"     = "PDT IT-Donor Engagement"
          + "data-classification"  = "high"
          + "environment-id"       = "Production"
          + "it-business-owner"    = "dl.It_Databricks_Admins@takeda.com"
          + "project-id"           = "APMS-93453"
        }
      + default_tags                 = (known after apply)
      + driver_instance_pool_id      = (known after apply)
      + driver_node_type_id          = "i3.4xlarge"
      + enable_elastic_disk          = (known after apply)
      + enable_local_disk_encryption = (known after apply)
      + id                           = (known after apply)
      + node_type_id                 = "i3.4xlarge"
      + num_workers                  = 0
      + policy_id                    = "9C61EF4F9600347C"
      + spark_conf                   = {
          + "spark.databricks.acl.dfAclsEnabled"                  = "false"
          + "spark.databricks.hive.metastore.glueCatalog.enabled" = "true"
          + "spark.databricks.repl.allowedLanguages"              = "python,sql"
          + "spark.hadoop.aws.glue.cache.db.enable"               = "true"
          + "spark.hadoop.aws.glue.cache.db.size"                 = "1000"
          + "spark.hadoop.aws.glue.cache.db.ttl-mins"             = "30"
          + "spark.hadoop.aws.glue.cache.table.enable"            = "true"
          + "spark.hadoop.aws.glue.cache.table.size"              = "1000"
          + "spark.hadoop.aws.glue.cache.table.ttl-mins"          = "30"
          + "spark.hadoop.fs.s3a.acl.default"                     = "BucketOwnerFullControl"
          + "spark.hadoop.hive.metastore.glue.catalogid"          = "432372222409"
        }
      + spark_version                = "10.4.x-scala2.12"
      + state                        = (known after apply)
      + url                          = (known after apply)

      + autoscale {
          + max_workers = 12
          + min_workers = 4
        }

      + aws_attributes {
          + availability           = "SPOT_WITH_FALLBACK"
          + first_on_demand        = 2
          + instance_profile_arn   = "arn:aws:iam::824757673730:instance-profile/TEC-EC2-DATABRICKS-USPRD-DS-PDT-FORECAST-ROLE"
          + spot_bid_price_percent = 100
          + zone_id                = "auto"
        }
    }

  # module.ds-pdt-forecast-dev_interactive_cluster.databricks_permissions.template will be created
  + resource "databricks_permissions" "template" {
      + cluster_id  = (known after apply)
      + id          = (known after apply)
      + object_type = (known after apply)

      + access_control {
          + group_name       = "Okta-DBX-E2-PDT-FORECAST-AppAdmin"
          + permission_level = "CAN_RESTART"
        }
      + access_control {
          + group_name       = "Okta-DBX-E2-PDT-FORECAST-DataScientist"
          + permission_level = "CAN_RESTART"
        }
    }

Plan: 7 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + ds-pdt-forecast-dev_interactive_cluster = (known after apply)

─────────────────────────────────────────────────────────────────────────────

Saved the plan to: plan.json

To perform exactly these actions, run the following command to apply:
    terraform apply "plan.json"
