Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create
  ~ update in-place

Terraform will perform the following actions:

  # databricks_job.create_comm_crm_vws_27910 will be created
  + resource "databricks_job" "create_comm_crm_vws_27910" {
      + always_running      = false
      + format              = (known after apply)
      + id                  = (known after apply)
      + max_concurrent_runs = 1
      + name                = "Create_COMM_CRM_VWs"
      + url                 = (known after apply)

      + email_notifications {
          + on_failure = [
              + "awadhesh.yona@takeda.com",
            ]
        }

      + schedule {
          + pause_status           = "PAUSED"
          + quartz_cron_expression = "0 0 17 * * ?"
          + timezone_id            = "US/Eastern"
        }

      + task {
          + existing_cluster_id = "0110-142743-w40tjrzq"
          + retry_on_timeout    = (known after apply)
          + task_key            = "Create_COMM_CRM_VWs"

          + notebook_task {
              + notebook_path = "/COMM/COMM_IT_GEM/CDP/Notebook_Master"
            }
        }
    }

  # databricks_job.uk_notebook_79518 will be created
  + resource "databricks_job" "uk_notebook_79518" {
      + always_running      = false
      + format              = (known after apply)
      + id                  = (known after apply)
      + max_concurrent_runs = 1
      + name                = "UK-NOTEBOOK"
      + url                 = (known after apply)

      + email_notifications {}

      + task {
          + existing_cluster_id = "0110-142743-w40tjrzq"
          + retry_on_timeout    = (known after apply)
          + task_key            = "UK-NOTEBOOK"

          + notebook_task {
              + notebook_path = "/Users/sudhansu.sekhar-pani@takeda.com/UK-TEST-NOTEBOOK"
            }
        }
    }

  # databricks_job.uk_notebook_test_79529 will be created
  + resource "databricks_job" "uk_notebook_test_79529" {
      + always_running      = false
      + format              = (known after apply)
      + id                  = (known after apply)
      + max_concurrent_runs = 1
      + name                = "UK-NOTEBOOK-TEST"
      + url                 = (known after apply)

      + email_notifications {}

      + task {
          + existing_cluster_id = "0110-142743-w40tjrzq"
          + retry_on_timeout    = (known after apply)
          + task_key            = "UK-NOTEBOOK-TEST"

          + notebook_task {
              + notebook_path = "/EUCAN/DQC/UK - HDSC - PK testing"
            }
        }
    }

  # databricks_permissions.job_create_comm_crm_vws_27910 will be created
  + resource "databricks_permissions" "job_create_comm_crm_vws_27910" {
      + id          = (known after apply)
      + job_id      = (known after apply)
      + object_type = (known after apply)

      + access_control {
          + permission_level = "CAN_MANAGE"
          + user_name        = "aditya.sonar@takeda.com"
        }
      + access_control {
          + permission_level = "CAN_MANAGE"
          + user_name        = "vishwanathan.iyer@takeda.com"
        }
    }

  # databricks_permissions.job_uk_notebook_79518 will be created
  + resource "databricks_permissions" "job_uk_notebook_79518" {
      + id          = (known after apply)
      + job_id      = (known after apply)
      + object_type = (known after apply)

      + access_control {
          + permission_level       = "CAN_MANAGE_RUN"
          + service_principal_name = "55ecc3f3-dc02-4d69-9da5-d021a171005e"
        }
    }

  # databricks_permissions.job_uk_notebook_test_79529 will be created
  + resource "databricks_permissions" "job_uk_notebook_test_79529" {
      + id          = (known after apply)
      + job_id      = (known after apply)
      + object_type = (known after apply)

      + access_control {
          + permission_level       = "CAN_MANAGE_RUN"
          + service_principal_name = "55ecc3f3-dc02-4d69-9da5-d021a171005e"
        }
    }

  # module.de-com-eucan-da_interactive_cluster.databricks_cluster.template will be updated in-place
  ~ resource "databricks_cluster" "template" {
      ~ custom_tags                  = {
          - "apms-id"              = "APMS-91706" -> null
          - "application-name"     = "databricks" -> null
          - "it-technical-owner"   = "dl.Ted-Platform-Team@Takeda.com" -> null
          - "ops-exclude-patch"    = "RITM0590559" -> null
            # (12 unchanged elements hidden)
        }
        id                           = "0110-142743-w40tjrzq"
      ~ spark_conf                   = {
          - "spark.databricks.delta.autoCompact.enabled"          = "true" -> null
          - "spark.databricks.delta.optimizeWrite.enabled"        = "true" -> null
            # (11 unchanged elements hidden)
        }
        # (14 unchanged attributes hidden)

        # (2 unchanged blocks hidden)
    }

  # module.de-com-eucan-da_interactive_cluster.databricks_permissions.template will be updated in-place
  ~ resource "databricks_permissions" "template" {
        id          = "/clusters/0110-142743-w40tjrzq"
        # (2 unchanged attributes hidden)

      - access_control {
          - permission_level = "CAN_MANAGE" -> null
          - user_name        = "ipsita.patra@takeda.com" -> null
        }
      - access_control {
          - group_name       = "Okta-DBX-E2-COM-GEMEUCAN-AppAdmin" -> null
          - permission_level = "CAN_RESTART" -> null
        }
      + access_control {
          + group_name       = "Okta-DBX-E2-COM-GEMEUCAN-AppAdmin"
          + permission_level = "CAN_RESTART"
        }
      - access_control {
          - group_name       = "Okta-DBX-E2-COM-GEMEUCAN-DataScientist" -> null
          - permission_level = "CAN_RESTART" -> null
        }
      + access_control {
          + group_name       = "Okta-DBX-E2-COM-GEMEUCAN-DataScientist"
          + permission_level = "CAN_RESTART"
        }
    }

Plan: 6 to add, 2 to change, 0 to destroy.

─────────────────────────────────────────────────────────────────────────────

Saved the plan to: plan.json

To perform exactly these actions, run the following command to apply:
    terraform apply "plan.json"
